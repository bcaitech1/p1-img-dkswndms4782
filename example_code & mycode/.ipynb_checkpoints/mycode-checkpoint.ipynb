{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "speaking-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "christian-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "trian_dir = '/opt/ml/input/data/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-evidence",
   "metadata": {},
   "source": [
    "# 1.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quiet-liver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,name='cnn',xdim=[1,512,384],\n",
    "                 ksize=3,cdims=[32,64],hdims=[1024,128],ydim=18,\n",
    "                 USE_BATCHNORM=True):\n",
    "        super(CNN,self).__init__()\n",
    "        self.name = name\n",
    "        self.xdim = xdim\n",
    "        self.ksize = ksize\n",
    "        self.cdims = cdims\n",
    "        self.hdims = hdims\n",
    "        self.ydim = ydim\n",
    "        self.USE_BATCHNORM = USE_BATCHNORM\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.layers = []\n",
    "        prev_cdim = self.xdim[0]\n",
    "        for cdim in self.cdims: # for each hidden layer\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels = prev_cdim, \n",
    "                    out_channels = cdim,\n",
    "                    kernel_size = self.ksize,\n",
    "                    stride = (1,1),\n",
    "                    padding = self.ksize//2\n",
    "                  )\n",
    "                ) # convlution \n",
    "            if self.USE_BATCHNORM:\n",
    "                self.layers.append(nn.BatchNorm2d(cdim)) # batch-norm\n",
    "            self.layers.append(nn.ReLU(True))  # activation\n",
    "            self.layers.append(nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))) # max-pooling \n",
    "            self.layers.append(nn.Dropout2d(p=0.5))  # dropout\n",
    "            prev_cdim = cdim\n",
    "\n",
    "        # Dense layers\n",
    "        self.layers.append(nn.Flatten())\n",
    "        prev_hdim = prev_cdim*(self.xdim[1]//(2**len(self.cdims)))*(self.xdim[2]//(2**len(self.cdims)))\n",
    "        for hdim in self.hdims:\n",
    "            self.layers.append(nn.Linear(\n",
    "                in_features = prev_hdim,\n",
    "                out_features = hdim,\n",
    "                bias = True))\n",
    "            self.layers.append(nn.ReLU(True))  # activation\n",
    "            prev_hdim = hdim\n",
    "        # Final layer (without activation)\n",
    "        self.layers.append(nn.Linear(prev_hdim,self.ydim,bias=True))\n",
    "\n",
    "        # Concatenate all layers \n",
    "        self.net = nn.Sequential()\n",
    "        for l_idx,layer in enumerate(self.layers):\n",
    "            layer_name = \"%s_%02d\"%(type(layer).__name__.lower(),l_idx)\n",
    "            self.net.add_module(layer_name,layer)\n",
    "        self.init_param() # initialize parameters\n",
    "        \n",
    "    def init_param(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d): # init conv\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m,nn.BatchNorm2d): # init BN\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear): # lnit dense\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "C = CNN(\n",
    "    name='cnn',xdim=[1,512,384],ksize=3,cdims=[32,64],\n",
    "    hdims=[1024, 128],ydim=10).to('cuda')\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optm = optim.Adam(C.parameters(),lr=1e-3)\n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-bracelet",
   "metadata": {},
   "source": [
    "# 2.Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-preservation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
